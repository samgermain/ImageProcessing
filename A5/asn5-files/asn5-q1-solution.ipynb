{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1:  Implement the Histogram of Curvature Scale\n",
    "\n",
    "Write a function called HoCS that returns a histogram of curvature scale feature vector for a given region.  The inputs to your function should be:\n",
    "\n",
    "- `B`: a binary that contains exactly one foreground connected component.\n",
    "- `min_scale`: The samllest scale (circle radius) at which to calcluate curvature\n",
    "- `max_scale`: The largest scale (circle radius) at which to calculate curvature\n",
    "- `increment`: The increment at which intermediate curvatures should be calculated (must be a positive integer)\n",
    "- `num_bins`: The number of bins in the histogram of curvature for a single scale (must be a positive integer)\n",
    "\n",
    "Your function should compute a histogram of curvature for each scale, starting at `min_scale` ending at (at most) `max_scale`, and for intermediate scales at increments of `increment`.  For example, if `min_scale`=4 and `max_scale`=20, and `increment`=3, then the function should compute a histogram of curvature for scales 4, 7, 10, 13, 16, and 19.  Each histogram at each scale should have `num_bins` bins.  Curvature must be computed using the normalized area integral invariant method described on Slide 39 of the Topic 9 lecture notes.  \n",
    "\n",
    "Normalize each histogram at each scale.\n",
    "\n",
    "To keep things straightforward, your functions hould only consider the outer perimeter of the input region; ignore the boundaries of holes in the region.\n",
    "\n",
    "After computing the histogram of curvature at each of the specified scales, all of the histograms should be concatenated into a single one-dimensional array (feature vector) and then returned.\n",
    "\n",
    "_Implementation hint:  You can calculate the normalized area integral invariant of each pixel efficiently using linear filtering.  You will find the function `skimage.morphology.disk()` function useful for designing the appropriate filter masks._\n",
    "\n",
    "_Implementation hint:  Most of the heavy lifting here can be done with module functions from `skimage`, `numpy`, and `scipy`.  Many of the functions mentioned in class and in the notes will be useful.  One that we might not have covered, but will be very handy is `numpy.histogram()`.  When use use it, makes sure you specify both the `bins` and `range` optional arguments.  Also note that `numpy.histogram()` returns TWO things.  You only need the first one, so make sure you write your function call like this:_\n",
    "\n",
    "`the_histogram, stuff_you_dont_need = np.histogram(...)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as nd\n",
    "import skimage.segmentation as seg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.morphology as morph\n",
    "import skimage.util as util\n",
    "import skimage.transform as trans\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def HoCS(B, min_scale, max_scale, increment, num_bins):\n",
    "    '''\n",
    "    Computes a histogram of curvature scale for the shape in the binary image B.  \n",
    "    Boundary fragments due to holes are ignored.\n",
    "    :param B: A binary image consisting of a single foreground connected component.\n",
    "    :param min_scale: smallest scale to consider (minimum 1)\n",
    "    :param max_scale: largest scale to consider (max_scale > min_scale)\n",
    "    :param increment:  increment on which to compute scales between min_scale and max_scale\n",
    "    :param num_bins: number of bins for the histogram at each scale\n",
    "    :return: 1D array of histograms concatenated together in order of increasing scale.\n",
    "    \n",
    "    Note: a curvature values are between 0.0 and 1.0 are interpreted thusly:\n",
    "       0.0 - values close to 0 arise from highly convex points.\n",
    "       0.5 - no curvature\n",
    "       1.0 - values close to 1 arise from highly concave points.\n",
    "\n",
    "    This solution uses the Area Integeral Invariant from:\n",
    "\n",
    "    Siddharth Manay, Daniel Cremers, Byung-Woo Hong, Anthony J. Yezzi and Stefano\n",
    "    Soatto.  Integral Invariants for Shape Matching, IEEE Transactions on Pattern\n",
    "    Analysis and Machine Intelligence, Vol 28, No. 10, pp. 1602-1618, 2006.\n",
    " \n",
    "    And combines it with the curvature scale histogramming technique used in:\n",
    "\n",
    "    Neeraj Kumar, Peter N. Belhumeur, Arijit Biswas, David W. Jacobs, W. John Kress,\n",
    "    Ida Lopez, Jo√£o V. B. Soares.  Leafsnap: A Computer Vision System for Automatic\n",
    "    Plant Species Identification, Proceedings of the 12th European Conference on\n",
    "    Computer Vision (ECCV), 2012.\n",
    "    '''\n",
    "    \n",
    "    # Check input validity\n",
    "    if max_scale < min_scale:\n",
    "        raise ValueError('max_scale must be larger than min_scale')\n",
    "    \n",
    "    if num_bins < 1:\n",
    "        raise ValueError('num_bins must be >= 1')\n",
    "    \n",
    "    # Assume B has only one connected component\n",
    "    b_holes_filled = nd.binary_fill_holes(B)\n",
    "    \n",
    "    # Get the locations boundary points using the method on slide 71 of Topic 06.\n",
    "    bp = np.where(seg.find_boundaries(b_holes_filled, connectivity=1, mode='inner') > 0)\n",
    "    bp = np.transpose(np.vstack(bp))\n",
    "    \n",
    "    # iterate over scales\n",
    "    histograms = []\n",
    "    for radius in np.arange(min_scale, max_scale+1, increment):\n",
    "\n",
    "        # Construct linear filter for calculating area integral invariant.\n",
    "        # divide disk mask by number of 1-entries, this will respond as the \n",
    "        # percentage of 1-entries that are covering the foreground region \n",
    "        # at each pixel.\n",
    "        disk = morph.disk(radius) \n",
    "        disk = disk / np.sum(disk)\n",
    "        \n",
    "        # Filter the input image -- gotta convert it to float first or the output will be boolean\n",
    "        # (which is bad because all our filter responses would get rounded to zero).\n",
    "        c = nd.filters.convolve(util.img_as_float(b_holes_filled), disk)\n",
    "            \n",
    "        # extract the filter response for boundary pixels only.\n",
    "        curvatures= c[bp[:,0], bp[:,1]]\n",
    "        \n",
    "        # Get the histogram of the curvatures extracted and append to the list of histograms for each scale.\n",
    "        h, bin_edges = np.histogram(curvatures, bins=num_bins, range=(0.0,1.0))\n",
    "        histograms.append(h / len(curvatures))\n",
    "        \n",
    "    # Horizontally concatenate all the histograms and return the resulting array.\n",
    "    return np.hstack(histograms)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test your HoCS function.\n",
    "\n",
    "Run HoCS on `threshimage_0001.png` from the ground truth for assignment 3.  Use `min_scale=5`, `max_scale=25`, `increment=10`, `num_bins=10`.  Plot the resulting feature vector as a bar graph.  Set the y-axis limits to be between 0.0 and 1.0.  You should get a result that matches the sample output in the assignment description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from uint8 to bool\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "min_scale=5\n",
    "max_scale=25\n",
    "increment=10\n",
    "num_bins=10\n",
    "\n",
    "B = util.img_as_bool(io.imread('leaftraining/threshimage_0001.png'))\n",
    "\n",
    "feature = HoCS(B, min_scale, max_scale, increment, num_bins)\n",
    "\n",
    "plt.bar(range(len(feature)), feature)\n",
    "plt.ylim((0,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate training features.\n",
    "\n",
    "Use your function from Step 1 to compute the HoCS feature for each of the training images.  Use them to train a k-nearest neigbour classifier.  It is up to you to determine the parameters for the HoCS feature such as `min_scale`, `max_scale`, etc. to maximize the classification rate.  This will require some experimentation.  Slides 19-12 of Topic 12 lecture notes will be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features for threshimage_0160.png\n",
      "Calculating features for threshimage_0174.png\n",
      "Calculating features for threshimage_0175.png\n",
      "Calculating features for threshimage_0161.png\n",
      "Calculating features for threshimage_0001.png\n",
      "Calculating features for threshimage_0015.png\n",
      "Calculating features for threshimage_0163.png\n",
      "Calculating features for threshimage_0162.png\n",
      "Calculating features for threshimage_0002.png\n",
      "Calculating features for threshimage_0166.png\n",
      "Calculating features for threshimage_0007.png\n",
      "Calculating features for threshimage_0011.png\n",
      "Calculating features for threshimage_0005.png\n",
      "Calculating features for threshimage_0165.png\n",
      "Calculating features for threshimage_0171.png\n",
      "Calculating features for threshimage_0010.png\n",
      "Calculating features for threshimage_0089.png\n",
      "Calculating features for threshimage_0100.png\n",
      "Calculating features for threshimage_0105.png\n",
      "Calculating features for threshimage_0104.png\n",
      "Calculating features for threshimage_0110.png\n",
      "Calculating features for threshimage_0099.png\n",
      "Calculating features for threshimage_0113.png\n",
      "Calculating features for threshimage_0080.png\n",
      "Calculating features for threshimage_0078.png\n",
      "Calculating features for threshimage_0090.png\n",
      "Calculating features for threshimage_0132.png\n",
      "Calculating features for threshimage_0009.png\n",
      "Calculating features for threshimage_0018.png\n",
      "Calculating features for threshimage_0019.png\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "\n",
    "# Create a class label vector for the training images.\n",
    "labels = np.ones(10, dtype='int')\n",
    "training_labels = np.hstack( (labels, labels*2, labels *3) )\n",
    "\n",
    "min_scale=5\n",
    "max_scale=30\n",
    "increment=5\n",
    "num_bins=15\n",
    "\n",
    "# Calculate the feature vectors for the training images\n",
    "training = []\n",
    "for root, dirs, files in os.walk('./leaftraining'):\n",
    "    for f in files:\n",
    "        if f[-4:] == '.png':\n",
    "            print('Calculating features for', f)\n",
    "            B = io.imread(os.path.join(root, f))\n",
    "            features = HoCS(B, min_scale, max_scale, increment, num_bins)\n",
    "            training.append(features)\n",
    "            \n",
    "training = np.vstack(training)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train the KNN classifier using the feature vectors from the training images.\n",
    "\n",
    "You have another opportunity here to optimize parameters.  You can experiment with the options for the KNN classifier (in partiuclar n_neighbors) to try to obtain better classification rates.  But you won't really be able to do this until after step 6, so just use default parameters to start with. \n",
    "\n",
    "Hint: The steps in this notebook are broken up the way they are so that you can adjust the parameters of training tye classifier and then go and perform the classfication without having to re-run the calculation of the features in steps 3 and 5.  You can adjust the parameters here in step 4, and then go and re-run the test set in Step 6 without running step 5 over again -- which is good because step 5 will take a while to run.  Of course you will have to recalculate the features each time you restart PyCharm or the Jupyter Notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the KNN classifier\n",
    "import sklearn.neighbors as neigh\n",
    "\n",
    "KNN = neigh.KNeighborsClassifier(n_neighbors=1)\n",
    "KNN.fit(training, training_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Calculate the testing features.\n",
    "\n",
    "Compute the HoCS features for all of the testing images.  Use the same HoCS parameters you did in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features for image_0185.png\n",
      "Calculating features for image_0152.png\n",
      "Calculating features for image_0146.png\n",
      "Calculating features for image_0026.png\n",
      "Calculating features for image_0033.png\n",
      "Calculating features for image_0027.png\n",
      "Calculating features for image_0147.png\n",
      "Calculating features for image_0153.png\n",
      "Calculating features for image_0184.png\n",
      "Calculating features for image_0186.png\n",
      "Calculating features for image_0179.png\n",
      "Calculating features for image_0145.png\n",
      "Calculating features for image_0151.png\n",
      "Calculating features for image_0031.png\n",
      "Calculating features for image_0025.png\n",
      "Calculating features for image_0024.png\n",
      "Calculating features for image_0030.png\n",
      "Calculating features for image_0150.png\n",
      "Calculating features for image_0144.png\n",
      "Calculating features for image_0178.png\n",
      "Calculating features for image_0140.png\n",
      "Calculating features for image_0154.png\n",
      "Calculating features for image_0168.png\n",
      "Calculating features for image_0034.png\n",
      "Calculating features for image_0020.png\n",
      "Calculating features for image_0009.png\n",
      "Calculating features for image_0021.png\n",
      "Calculating features for image_0035.png\n",
      "Calculating features for image_0155.png\n",
      "Calculating features for image_0141.png\n"
     ]
    }
   ],
   "source": [
    "# Create a class label vector for the testing images.\n",
    "labels1 = np.ones(50, dtype='int')\n",
    "labels2 = np.ones(27, dtype='int')\n",
    "labels3 = np.ones(52, dtype='int')\n",
    "\n",
    "testing_labels = np.hstack( (labels1, labels2*2, labels3*3) )\n",
    "\n",
    "# Calculate the feature vectors for the testing images\n",
    "testing = []\n",
    "for root, dirs, files in os.walk('./leaftesting'):\n",
    "    for f in files:\n",
    "        if f[-4:] == '.png':\n",
    "            print('Calculating features for', f)\n",
    "            B = io.imread(os.path.join(root, f))\n",
    "            features = HoCS(B, min_scale, max_scale, increment, num_bins)\n",
    "            testing.append(features)\n",
    "            \n",
    "testing = np.vstack(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Classfiy the testing features.\n",
    "\n",
    "Classify the training features.\n",
    "\n",
    "Determine the classification rate and the confusion matrix by comparing the results of the classifier to the true class labels for each image.  \n",
    "\n",
    "Print out the filenames of incorrectly classified images.\n",
    "\n",
    "Print the confusion matrix (you don't have to print the row/column indicies as in the example in the assignment description), just the rows and columns of the matrix itself.   Confusion matrix is explained in the background section of the assignment description document.\n",
    "\n",
    "Print the correct classification rate.  Classification rate is explained in the Topic 12 notes and in the background section of the assignment description document.\n",
    "\n",
    "It should be very easy to get a classficiation rate more than 90%; with well-chosen parameters for your HoCS features and the KNN classifier you should be able to get as much as 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNN' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5a41288b01bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Construct a boolean array that denotes which images were correctly classified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtesting_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNN' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "predictions = KNN.predict(testing)\n",
    "\n",
    "# Construct a boolean array that denotes which images were correctly classified.\n",
    "correct_labels = predictions==testing_labels\n",
    "\n",
    "# obtain the filenames of images that were incorrectly classified.\n",
    "incorrectly_classified = [ files[i] for i in range(len(files)) if not correct_labels[i] ]\n",
    "\n",
    "# Print out the names of incorrectly classified images.\n",
    "for f in incorrectly_classified:\n",
    "    print(f, 'was incorrectly classified.')\n",
    "print()  \n",
    "    \n",
    "# Compute and print out the confusion matrix.\n",
    "confusion = np.zeros((3, 3), dtype='int')\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    confusion[testing_labels[i]-1, predictions[i]-1] += 1\n",
    "    \n",
    "print('The confusion matrix is:')\n",
    "for x in confusion:\n",
    "    print('{:5}, {:5}, {:5}'.format(x[0], x[1], x[2]))\n",
    "print()\n",
    "\n",
    "# Compute and print out the classification rate.\n",
    "correct_rate = np.sum(correct_labels) / len(predictions)\n",
    "print('The classification rate was', correct_rate*100, 'percent.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Reflections\n",
    "\n",
    "Answer the following questions right here in this block:\n",
    "\n",
    "- Discuss your HoCS parameters and how you arrived at them.  Why did you choose the scales and number of histogram bins that you did?  Are there other values that work just as well?   Likely you tested other HoCS parameters that resulted in worse performance before finding the ones that worked best -- what were some of them and why do you think the performance was worse?\n",
    "\n",
    "\t_Your answer:_\n",
    "\n",
    "- Discuss your choice of KNN classifier parameters and how you arrived at them (think about the same types of questions as in the previous point).\n",
    "\n",
    "\t_Your answer:_\n",
    "\n",
    "- Discuss the misclassified images.  Were there any classes that were particularly difficult to distinguish?  Is there anything unusual about any of the misclassified images that would cuase them to be misclassified?  If so, explain\n",
    "\n",
    "\t_Your answer:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
