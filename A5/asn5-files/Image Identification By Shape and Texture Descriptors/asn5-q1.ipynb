{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1:  Implement the Histogram of Curvature Scale\n",
    "\n",
    "Write a function called HoCS that returns a histogram of curvature scale feature vector for a given region.  The inputs to your function should be:\n",
    "\n",
    "- `B`: a binary image that contains exactly one foreground connected component.\n",
    "- `min_scale`: The smallest scale (circle radius) at which to calcluate curvature\n",
    "- `max_scale`: The largest scale (circle radius) at which to calculate curvature\n",
    "- `increment`: The increment at which intermediate curvatures should be calculated (must be a positive integer)\n",
    "- `num_bins`: The number of bins in the histogram of curvature for a single scale (must be a positive integer)\n",
    "\n",
    "Your function should compute a histogram of curvature for each scale, starting at `min_scale` ending at (at most) `max_scale`, and for intermediate scales at increments of `increment`.  For example, if `min_scale`=4 and `max_scale`=20, and `increment`=3, then the function should compute a histogram of curvature for scales 4, 7, 10, 13, 16, and 19.  Each histogram at each scale should have `num_bins` bins.  Curvature must be computed using the normalized area integral invariant method described on Slide 39 of the Topic 9 lecture notes.  \n",
    "\n",
    "Normalize each histogram at each scale.\n",
    "\n",
    "To keep things straightforward, your functions hould only consider the outer perimeter of the input region; ignore the boundaries of holes in the region.\n",
    "\n",
    "After computing the histogram of curvature at each of the specified scales, all of the histograms should be concatenated into a single one-dimensional array (feature vector) and then returned.\n",
    "\n",
    "_Implementation hint:  You can calculate the normalized area integral invariant of each pixel efficiently using linear filtering.  You will find the function `skimage.morphology.disk()` function useful for designing the appropriate filter masks._\n",
    "\n",
    "_Implementation hint:  Most of the heavy lifting here can be done with module functions from `skimage`, `numpy`, and `scipy`.  Many of the functions mentioned in class and in the notes will be useful.  One that we might not have covered, but will be very handy is `numpy.histogram()`.  When you use it, makes sure you specify both the `bins` and `range` optional arguments. Also note that `numpy.histogram()` returns TWO things.  You only need the first one, so make sure you write your function call like this:_\n",
    "\n",
    "`the_histogram, stuff_you_dont_need = np.histogram(...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "#    norm1 = x / np.linalg.norm(x)\n",
    "#    norm2 = normalize(x[:, np.newaxis], axis=0).ravel()\n",
    "#    return np.all(norm1 == norm2)\n",
    "    return (v - min(v))/(max(v)-min(v))\n",
    "\n",
    "def HoCS(B, min_scale, max_scale, increment, num_bins):\n",
    "    '''\n",
    "     Computes a histogram of curvature scale for the shape in the binary image B.\n",
    "    Boundary fragments due to holes are ignored.\n",
    "    :param B: A binary image consisting of a single foreground connected component.\n",
    "    :param min_scale: smallest scale to consider (minimum 1)\n",
    "    :param max_scale: largest scale to consider (max_scale > min_scale)\n",
    "    :param increment:  increment on which to compute scales between min_scale and max_scale\n",
    "    :param num_bins: number of bins for the histogram at each scale\n",
    "    :return: 1D array of histograms concatenated together in order of increasing scale.\n",
    "    '''\n",
    "\n",
    "    #print(B)\n",
    "    #outline = np.logical_and(B,morph.binary_erosion(B))  # Get the border pixels of the binary image\n",
    "    outline = seg.find_boundaries(B, connectivity=2, mode='inner')\n",
    "    #outlin = outline(B)\n",
    "    #print(\"outline:\", outline)\n",
    "    # Save all the outline coordinates\n",
    "    o_index = np.argwhere(outline == True)  # 2d array of two columns, row# and col# in each column\n",
    "    #print(B[o_index[0][0]][o_index[0][1]])\n",
    "    #print(o_index)\n",
    "    # Create a 2d histogram to save of the histogram of curvature scales\n",
    "    scales = int(((max_scale - min_scale) / increment) + 1)\n",
    "    final_array = np.array([])\n",
    "    #i = 0\n",
    "    pd = 500\n",
    "    B2 = np.pad(B,((pd,pd),(pd,pd)),'edge')\n",
    "\n",
    "    # Loop through each scale\n",
    "    for scale in range(min_scale, max_scale+1, increment):\n",
    "        # print(o_index[:][0])\n",
    "        hist_cur = np.zeros(len(o_index))\n",
    "        disk = morph.disk(scale, dtype=bool)\n",
    "        num_pix = np.count_nonzero(disk == 1)\n",
    "        for pix in range(0, len(o_index)):\n",
    "            # calculate how many 1 pixels in radius at o_index[pix][0],o_index[pix][1]\n",
    "            # Calculate the normalized area integral invariant\n",
    "            l = o_index[pix][0] - scale  # left\n",
    "            r = o_index[pix][0] + scale  + 1# right\n",
    "            u = o_index[pix][1] - scale  # above\n",
    "            d = o_index[pix][1] + scale  + 1# below\n",
    "            #print(\"l:\", l, \"r:\", r, \"u:\", u, \"d:\", d)\n",
    "            #print(disk)\n",
    "            nbrhd = B2[l+pd:r+pd,u+pd:d+pd]  # neighboard about the outline pixel\n",
    "            #print(nbrhd)\n",
    "            overlap = np.logical_and(nbrhd, disk)  # fg pixels in the circle\n",
    "            fg = np.count_nonzero(overlap == 1)\n",
    "            kp = fg / (num_pix)  # normalized area integral invarient\n",
    "            hist_cur[pix] = kp\n",
    "            #print(\"fg:\", fg, \"kp:\", kp)\n",
    "            #if (pix == len(o_index)-1):\n",
    "            #    hist_cur = normalize(hist_cur)\n",
    "\n",
    "        # Save the histogram of curvature for this scale\n",
    "    #    print(hist_cur)\n",
    "        hist, other_stuff = np.histogram(hist_cur, bins=num_bins, range=(0.0,1.0))\n",
    "    #    print(hist)\n",
    "        #divide the histogram by the sum of all the bins\n",
    "        final_array = np.concatenate([final_array,hist])\n",
    "        #np.delete(final_array,0)\n",
    "        #i += 1\n",
    "    # reshape to a 1d array, this will be the concatted histograms\n",
    "    return final_array / int(o_index.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test your HoCS function.\n",
    "\n",
    "Run HoCS on `threshimage_0001.png` from the ground truth for assignment 3.  Use `min_scale=5`, `max_scale=25`, `increment=10`, `num_bins=10`.  Plot the resulting feature vector as a bar graph.  Set the y-axis limits to be between 0.0 and 1.0.  You should get a result that matches the sample output in the assignment description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "B = util.img_as_bool(io.imread('leaftraining/threshimage_0001.png'))\n",
    "y = HoCS(B, 5, 25, 10, 10)\n",
    "x = range(0,len(y))\n",
    "plt.bar(x,height=y)\n",
    "plt.ylim(0,1.0)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate training features.\n",
    "\n",
    "Use your function from Step 1 to compute the HoCS feature for each of the training images.  Use them to train a k-nearest neigbour classifier.  It is up to you to determine the parameters for the HoCS feature such as `min_scale`, `max_scale`, etc. to maximize the classification rate.  This will require some experimentation.  Slides 19-21 of Topic 12 lecture notes will be helpful here.\n",
    "\n",
    "Also generate the training labels here (a column-array of numbers indicating which descriptors belong to each class, e.g. use values 1,2,3 to indicate class 1, 2, and 3.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors as neigh\n",
    "import os as os\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "images = [os.path.basename(x) for x in glob.glob('leaftraining/*.png')]\n",
    "images.sort()\n",
    "length = len(images)\n",
    "\n",
    "min = 5\n",
    "max = 25\n",
    "inc = 8\n",
    "bins = 5\n",
    "\n",
    "hocs_feat = []\n",
    "for i in range(0, length):\n",
    "    B = util.img_as_bool(io.imread('leaftraining/' + images[i]))\n",
    "    hocs = HoCS(B, min, max, inc, bins)\n",
    "    hocs_feat.append(hocs)\n",
    "hocs_feat = np.asarray(hocs_feat)\n",
    "\n",
    "labels = np.zeros(length)\n",
    "clazz = 1\n",
    "for i in range(0,length):\n",
    "    if (i==10):\n",
    "        clazz = 2\n",
    "    elif (i==20):\n",
    "        clazz = 3\n",
    "    labels[i] = clazz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train the KNN classifier using the feature vectors from the training images.\n",
    "\n",
    "You have another opportunity here to optimize parameters.  You can experiment with the options for the KNN classifier (in partiuclar n_neighbors) to try to obtain better classification rates.  But you won't really be able to do this until after step 6, so just use default parameters to start with. \n",
    "\n",
    "Hint: The steps in this notebook are broken up the way they are so that you can adjust the parameters of training the classifier and then go and perform the classfication without having to re-run the calculation of the features in steps 3 and 5.  You can adjust the parameters here in step 4, and then go and re-run the test set in Step 6 without running step 5 over again -- which is good because step 5 will take a while to run.  Of course you will have to recalculate the features each time you restart PyCharm or the Jupyter Notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the KNN classifier\n",
    "\n",
    "import sklearn.neighbors as neighbors\n",
    "neighbs = 3\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=neighbs)\n",
    "knn.fit(hocs_feat, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Calculate the testing features.\n",
    "\n",
    "Compute the HoCS features for all of the testing images.  Use the same HoCS parameters you did in Step 3.  Also generate class labels for the testing image descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again use os.walk() to process the testing images\n",
    "images = [os.path.basename(x) for x in glob.glob('leaftesting/*.png')]\n",
    "length = len(images)\n",
    "\n",
    "hocs_feat = []\n",
    "for i in range(0, length):\n",
    "    B = util.img_as_bool(io.imread('leaftesting/' + images[i]))\n",
    "    hocs = HoCS(B, min, max, inc, bins)\n",
    "    hocs_feat.append(hocs)\n",
    "hocs_feat = np.asarray(hocs_feat)\n",
    "\n",
    "labels = knn.predict(hocs_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Classfiy the testing features.\n",
    "\n",
    "Classify the testing image features.\n",
    "\n",
    "Determine the classification rate and the confusion matrix by comparing the results of the classifier to the true class labels for each image.  \n",
    "\n",
    "Print out the filenames of incorrectly classified images.\n",
    "\n",
    "Print the confusion matrix (you don't have to print the row/column indicies as in the example in the assignment description), just the rows and columns of the matrix itself.\n",
    "\n",
    "Print the correct classification rate.\n",
    "\n",
    "It should be very easy to get a classficiation rate more than 90%; with care you should be able to get as much as 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-de780adfdd79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write your code for Step 6 here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclazz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Write your code for Step 6 here.\n",
    "\n",
    "true_labels = np.zeros(length)\n",
    "clazz = 1\n",
    "for i in range(0,length):\n",
    "    if (i==50):\n",
    "        clazz = 2\n",
    "    elif (i==77):\n",
    "        clazz = 3\n",
    "    true_labels[i] = clazz\n",
    "\n",
    "confusion = np.zeros((clazz,clazz))\n",
    "for i in range(0, len(true_labels)):\n",
    "    print(\"lt\", true_labels[i], \"l\", labels[i])\n",
    "    lt = int(true_labels[i])\n",
    "    l = int(labels[i])\n",
    "    confusion[lt-1, l-1] += 1\n",
    "\n",
    "print(\"Confusion Matrix\\n\", confusion)\n",
    "\n",
    "print(\"Classification rate: \", np.trace(confusion)/(np.sum(confusion)/2) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
